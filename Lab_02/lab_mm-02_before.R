# Esly russkie bukvy ne otobrajautsa: File -> Reopen with encoding... UTF-8

# Используйте UTF-8 как кодировку по умолчанию!
# Установить кодировку в RStudio: Tools -> Global Options -> General, 
#  Default text encoding: UTF-8

# ..............................................................................
# Математическое моделирование: Практика 2
#   Оценка точности модели с дискретной зависимой переменной (Y)
#      * как рассчитать матрицу неточностей
#      * как считать показатели качества модели по матрице неточностей
#      * как пользоваться наивным байесовским классификатором
#      * как пользоваться методом kNN (k ближайших соседей)
# ..............................................................................

library('class')          # функция knn()
library('e1071')          # функция naiveBayes()
library('MASS')           # функция mvrnorm()
library('emdbook')        # функция dmvnorm()

# ядро
my.seed <- 12345


# Генерируем данные ------------------------------------------------------------

#  Пример 2 ....................................................................
n <- 100               # наблюдений всего
train.percent <- 0.85  # доля обучающей выборки

# фактические значения объясняющих переменных (нормальный закон)
set.seed(my.seed)
x1 <- rnorm(20, 3.7, n = n)

set.seed(my.seed + 1)
x2 <- rnorm(50, 3.3, n = n)

# истинные дискриминирующие правила
rules <- function(x1, x2){
    ifelse((x1 > 20 & x2 < 50) | (x1 < 18 & x2 > 52), 1, 0)
}
# Конец данных примера 2 .......................................................

# Данные примера 3 .............................................................
n <- 100               # наблюдений всего
train.percent <- 0.85  # доля обучающей выборки

# x-ы -- двумерные нормальные случайные величины
set.seed(my.seed)
class.0 <- mvrnorm(45, mu = c(23, 49), 
                   Sigma = matrix(c(3.5^2, 0, 0, 3.4^2), 2, 2, byrow = T))

set.seed(my.seed + 1)
class.1 <- mvrnorm(55, mu = c(15, 51), 
                   Sigma = matrix(c(2^2, 0, 0, 2.5^2), 2, 2, byrow = T))

# записываем x-ы в единые векторы (объединяем классы 0 и 1)
x1 <- c(class.0[, 1], class.1[, 1])
x2 <- c(class.0[, 2], class.1[, 2])

# фактические классы Y
y <- c(rep(0, nrow(class.0)), rep(1, nrow(class.1)))

# классы для наблюдений сетки
rules.mv <- function(v.x, v.mean.y0, v.mean.y1, m.sigma.y0, m.sigma.y1){
    
    
}
# Конец данных примера 3 .......................................................


# Отбираем наблюдения в обучающую выборку --------------------------------------
set.seed(my.seed)
inTrain <- 
x1.train <- 
x2.train <- 
x1.test <- 
x2.test <- 

# Пример 2 .....................................................................
# используем истинные правила, чтобы присвоить фактические классы
y.train <- 
y.test <- 
# конец генерации классов для примера 2 ........................................
    
    
# Пример 3 .....................................................................
# используем истинные правила, чтобы присвоить фактические классы
y.train <- 
y.test <- 
# конец генерации классов для примера 3 ........................................
    
    
# фрейм с обучающей выборкой
df.train.1 <- data.frame(x1 = x1.train, x2 = x2.train, y = y.train)
# фрейм с тестовой выборкой
df.test.1 <- data.frame(x1 = x1.test, x2 = x2.test)


# Рисуем обучающую выборку графике ---------------------------------------------

# для сетки (истинных областей классов): целочисленные значения x1, x2
x1.grid <- rep(seq(floor(min(x1)), ceiling(max(x1)), by = 1),
               ceiling(max(x2)) - floor(min(x2)) + 1)
x2.grid <- rep(seq(floor(min(x2)), ceiling(max(x2)), by = 1),
               each = ceiling(max(x1)) - floor(min(x1)) + 1)

# классы для наблюдений сетки
# Пример 2 .....................................................................
y.grid <- 
# конец классов сетки для примера 2 ............................................

# Пример 3 .....................................................................
y.grid <- rules.mv(,
                   c(23, 49), c(15, 51), 
                   matrix(c(3.5^2, 0, 0, 3.4^2), 2, 2, byrow = T),
                   matrix(c(2^2, 0, 0, 2.5^2), 2, 2, byrow = T))
# конец классов сетки для примера 3 ............................................
        
# фрейм для сетки
df.grid.1 <- data.frame(x1 = x1.grid, x2 = x2.grid, y = y.grid)

# цвета для графиков
cls <- c('blue', 'orange')
cls.t <- c(rgb(0, 0, 1, alpha = 0.5), rgb(1,0.5,0, alpha = 0.5))

# график истинных классов
plot( 
     pch = '·', col = cls[df.grid.1[, 'y'] + 1],
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, факт')
# точки фактических наблюдений
points( 
       pch = 21, bg = cls.t[df.train.1[, 'y'] + 1], 
       col = cls.t[df.train.1[, 'y'] + 1])


# Байесовский классификатор ----------------------------------------------------
#  наивный байес: непрерывные объясняющие переменные

# строим модель
nb <- 
# получаем модельные значения на обучающей выборке как классы
y.nb.train <- 

    
# график истинных классов
plot( 
     pch = '·',  col = cls[df.grid.1[, 'y'] + 1], 
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, модель naiveBayes')
# точки наблюдений, предсказанных по модели
points(
       pch = 21, bg = cls.t[y.nb.train + 1], 
       col = cls.t[y.nb.train + 1])

# матрица неточностей на обучающей выборке
tbl <- 
tbl

# точность, или верность (Accuracy)
Acc <- 
Acc

# прогноз на тестовую выборку
y.nb.test <- 

# матрица неточностей на тестовой выборке
tbl <- 
tbl

# точность, или верность (Accuracy)
Acc <- 
Acc

# Метод kNN --------------------------------------------------------------------
#  k = 3

# строим модель и делаем прогноз
y.knn.train <- 

    
    
# график истинных классов
plot(
     pch = '·', col = cls[df.grid.1[, 'y'] + 1],
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, модель kNN')
# точки наблюдений, предсказанных по модели
points(
       pch = 21, bg = cls.t[as.numeric(y.knn.train)], 
       col = cls.t[as.numeric(y.knn.train)])

# матрица неточностей на обучающей выборке
tbl <- 
tbl

# точность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc

# прогноз на тестовую выборку
y.knn.test <- 

# матрица неточностей на тестовой выборке
tbl <- 
tbl

# точность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
