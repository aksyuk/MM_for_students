# Esly russkie bukvy ne otobrajautsa: File -> Reopen with encoding... UTF-8

# Используйте UTF-8 как кодировку по умолчанию!
# Установить кодировку в RStudio: Tools -> Global Options -> General, 
#  Default text encoding: UTF-8

# ..............................................................................
# Математическое моделирование: Практика 5
#   Кросс-валидация и бутстреп
#      * как оценить точность модели методом перекрёстной выборки;    
#      * методом проверочной выборки;    
#      * методом перекрёстной проверки по отдельным наблюдениям (LOOCV);   
#      * методом k-кратной перекрёстной проверки;   
#      * как применять бутстреп для оценки точности статистического параметра 
#        и оценок параметров модели   
# ..............................................................................

library('ISLR')             # набор данных Auto
library('GGally')           # матричные графики
library('boot')             # функция cv.glm(): расчёт ошибки с кросс-валидацией

my.seed <- 1

# Перекрёстная проверка --------------------------------------------------------

# Пример на данных по автомобилям: Auto {ISLR}
?Auto
DF.auto <- 
head(DF.auto)
summary(DF.auto)

# переводим дискретные количественные переменные в факторы
DF.auto$cylinders <- 
DF.auto$origin <- 
  

# графики разброса
ggpairs(DF.auto)
# только mpg ~ horsepower
plot(DF.auto$horsepower, DF.auto$mpg,
     xlab = 'horsepower', ylab = 'mpg', pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))

# Метод проверочной выборки ====================================================

# общее число наблюдений
n <- nrow(DF.auto)

# доля обучающей выборки
train.percent <- 0.5

# выбрать наблюдения в обучающую выборку
set.seed(my.seed)
inTrain <- 
inTrain

# факт на тестовой
y.test.fact <- 

# на графике
plot(
     xlab = 'horsepower', ylab = 'mpg', pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
points(DF.auto$horsepower[-inTrain], DF.auto$mpg[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), bg = rgb(1, 0, 0, alpha = 0.4))
legend('topright', 
       pch = c(16, 16), col = c('blue', 'red'), legend = c('test', 'train'))


# Линейная модель ##############################################################

# присоединить таблицу с данными: названия стоблцов будут доступны напрямую

# подгонка линейной модели на обучающей выборке
fit.lm.1 <- 
  
# прогноз на тестовую
y.test.lm.1 <- 

# считаем MSE на тестовой выборке
MSE.lm.1 <- 
# отсоединить таблицу с данными

# смотрим ошибку
MSE.lm.1


# Квадратичная модель ##########################################################

# присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(DF.auto)
# подгонка линейной модели на обучающей выборке
fit.lm.2 <- 
  
# прогноз на тестовую
y.test.lm.2 <- predict(fit.lm.2, DF.auto[-inTrain, ])

# считаем MSE на тестовой выборке
MSE.lm.2 <- round(mean((y.test.fact - y.test.lm.2)^2), 2)
# отсоединить таблицу с данными
detach(DF.auto)
# результат
MSE.lm.2


# Кубическая модель ############################################################

# присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(DF.auto)
# подгонка линейной модели на обучающей выборке
fit.lm.3 <- 
  
# прогноз на тестовую
y.test.lm.3 <- predict(fit.lm.3, DF.auto[-inTrain, ])
# считаем MSE на тестовой выборке
MSE.lm.3 <- round(mean((y.test.fact - y.test.lm.3)^2), 2)
# отсоединить таблицу с данными
detach(DF.auto)
# результат
MSE.lm.3


# Перекрёстная проверка по отдельным наблюдениям (LOOCV) =======================

# подгонка линейной модели на обучающей выборке
fit.glm <- 

# засекаем время начала расчётов
timer.start <- 
# считаем LOOCV-ошибку
cv.err <- 
# засекаем время окончания расчётов
timer.stop <- 

# результат: первое число -- по формуле LOOCV-ошибки,
#  второе -- с поправкой на смещение

# затраченное время

dim(DF.auto)

# оценим точность полиномиальных моделей, меняя степень
# вектор с LOOCV-ошибками
cv.err.loocv <- 
names(cv.err.loocv) <- 

# засекаем время начала расчётов
timer.start <- Sys.time()
# цикл по степеням полиномов
for (i in 1:5){
  fit.glm <- 
  cv.err.loocv[i] <- 
}
# засекаем время окончания расчётов
timer.stop <- Sys.time()

# результат
cv.err.loocv
# затраченное время
timer.stop - timer.start

# k-кратная перекрёстная проверка ==============================================

# оценим точность полиномиальных моделей, меняя степень
# вектор с ошибками по десятикратной кросс-валидации
cv.err.k.fold <- rep(0, 5)
names(cv.err.k.fold) <- 1:5

# засекаем время начала расчётов
timer.start <- Sys.time()

# цикл по степеням полиномов
for (i in 1:5) {
  fit.glm <- glm(mpg ~ poly(horsepower, i), data = DF.auto)
  cv.err.k.fold[i] <- 
    
}
# засекаем время окончания расчётов
timer.stop <- Sys.time()

# результат
cv.err.k.fold
# затраченное время
timer.stop - timer.start

# записываем все ошибки в таблицу
df.MSE <- data.frame(Модель = c('Линейная', 'Полином 2 степени',
                                'Полином 3 степени', 
                                rep(paste('Полином', 1:5, 'степени'), 2)), 
                     Проверка.точности = c(rep('Проверочная выборка 50%', 3),
                                           rep('LOOCV', 5), 
                                           rep('Кросс-валидация, k = 10', 5)),
                     MSE = round(c(MSE.lm.1, MSE.lm.2, MSE.lm.3, 
                                   cv.err.loocv, cv.err.k.fold), 2))
# все модели по возрастанию ошибки




# Бутстреп ---------------------------------------------------------------------

# Оценивание точности статистического параметра --------------------------------

# Пример с инвестиционным портфелем из двух активов: Portfolio {ISLR}
?Portfolio
head(Portfolio)
str(Portfolio)

# функция для вычисления искомого параметра
alpha.fn <- 
  
  
  
  

# рассчитать alpha по всем 100 наблюдениям


# создать бутстреп-выборку и повторно вычислить alpha
set.seed(my.seed)


# теперь -- многократное повторение предыдущей операции

### ORDINARY NONPARAMETRIC BOOTSTRAP
### Call:
###   boot(data = Portfolio, statistic = alpha.fn, R = 1000)
### Bootstrap Statistics :
###   original        bias    std. error
### t1* 0.5758321 -7.315422e-05  0.08861826

# Оценивание точности линейной регрессионной модели ----------------------------

# оценить стандартные ошибки параметров модели 
#  mpg = beta_0 + beta_1 * horsepower с помощью бутстрепа,
#  сравнить с оценками ошибок по МНК

# функция для расчёта коэффициентов ПЛР по выборке из данных
boot.fn <- 
  
  

### (Intercept)  horsepower 
### 39.9358610  -0.1578447

# пример применения функции к бутстреп-выборке
set.seed(my.seed)
boot.fn(DF.auto, sample(n, n, replace = T))
### (Intercept)  horsepower 
### 38.7387134  -0.1481952 

# применяем функцию boot для вычисления стандартных ошибок параметров
#  (1000 выборок с повторами)
boot(DF.auto, boot.fn, 1000)
### ORDINARY NONPARAMETRIC BOOTSTRAP
### Call:
###  boot(data = DF.auto, statistic = boot.fn, R = 1000)
### Bootstrap Statistics :
###   original        bias    std. error
### t1* 39.9358610  0.0299182398 0.862248138
### t2* -0.1578447 -0.0003205541 0.007429023

# сравним с ошибками параметров по МНК

# график остатков модели


# оценки отличаются из-за того, что МНК -- параметрический метод с допущениями,
#  и, судя по графику остатков, допущения не выполняются

# вычислим оценки параметров квадратичной модели регрессии
boot.fn.2 <- function(data, index){
  coef(lm(mpg ~ poly(horsepower, 2), data = data, subset = index))
}
# применим функцию к 1000 бутсреп-выборкам
set.seed(my.seed)

### ORDINARY NONPARAMETRIC BOOTSTRAP
### Call:
###   boot(data = DF.auto, statistic = boot.fn.2, R = 1000)
### 
### Bootstrap Statistics :
###   original       bias    std. error
### t1*   23.44592 -0.003660358   0.2195369
### t2* -120.13774  0.002769239   3.6138046
### t3*   44.08953  0.101767465   4.1998076

# сравним с ошибками параметров по МНК

# график остатков модели

