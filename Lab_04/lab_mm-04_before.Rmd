---
title: "Упражнение 4"
author: ""
date: '03 марта 2021 г '
output: html_document
---

Цель: исследовать набор данных `wages.ru` с помощью линейной регрессионной модели. Задействовав все возможные регрессоры, сделать вывод о пригодности модели для прогноза. Сравнить с методом k ближайших соседей по MSE на тестовой выборке.    

```{r Данные и пакеты, include = F}
# загрузка пакетов
library('GGally')
library('lmtest')
library('FNN')

# константы
my.seed <- 12345
train.percent <- 0.85

# загрузка данных
fileURL <- 'https://sites.google.com/a/kiber-guu.ru/msep/mag-econ/salary_data.csv?attredirects=0&d=1'

# преобразуем категориальные переменные в факторы
wages.ru <- read.csv(fileURL, row.names = 1, sep = ';', as.is = T)
wages.ru$male <- as.factor(wages.ru$male)
wages.ru$educ <- as.factor(wages.ru$educ)
wages.ru$forlang <- as.factor(wages.ru$forlang)

# обучающая выборка
set.seed(my.seed)
inTrain <- sample(seq_along(wages.ru$salary), 
                  nrow(wages.ru) * train.percent)
df.train <- wages.ru[inTrain, c(colnames(wages.ru)[-1], colnames(wages.ru)[1])]
df.test <- wages.ru[-inTrain, -1]

```

## Описание переменных  

Набор данных `wages` содержит переменные:  

- `salary` – среднемесячная зарплата после вычета налогов за последние 12 месяцев (рублей);  
- `male` – пол: **1** -- мужчина, **0** -- женщина;
- `educ` – уровень образования:  
**1** – 0-6 классов,  
**2** – незаконченное среднее (7-8 классов),  
**3** - незаконченное среднее плюс что-то ещё,  
**4** – законченное среднее,  
**5** – законченное среднее специальное, 
**6** – законченное высшее образование и выше;  
- `forlang` - иност. язык: **1** -- владеет, **0** – нет;
- `exper` – официальный стаж c 1.01.2002 (лет).

Размерность обучающей выборки: $n = `r dim(df.train)[1]`$ строк, $p = `r dim(df.train)[2] - 1`$ объясняющих переменных. Зависимая переменная -- `salary`.  

```{r Описание данных, echo = F, message = F, warning = F}
# описательные статистики по переменным


# совместный график разброса переменных


# цвета по фактору male
ggpairs(df.train[, c('exper', 'male', 'salary')], 
        aes(color = male), upper = list(combo = 'box'))

# цвета по фактору educ
ggpairs(df.train[, c('exper', 'educ', 'salary')], 
        aes(color = educ), upper = list(combo = 'box'))

# цвета по фактору forlang
ggpairs(df.train[, c('exper', 'forlang', 'salary')], 
        aes(color = forlang), upper = list(combo = 'box'))

```

## Модели  

```{r echo = F, warning = F, error = F}

model.1 <- 

```

Совместное влияние `exper:educ` исключаем, т.к. параметры незначимы и недостаточно наблюдений для оценки одного из них.   

```{r echo = F, warning = F, error = F}

model.2 <- 
  
```

Взаимодействие `male1:exper` также исключаем.  

```{r echo = F, warning = F, error = F}

model.3 <- 

```

Коэффициент при `forlang1` наименее значимый, и его знак не соответствует здравому смыслу.   

```{r echo = F, warning = F, error = F}

model.4 <- 

```

В модели практически нет значимых объясняющих переменных. Вероятно, это из-за того, что подвыборки по уровням фактора `educ` очень маленькие. Попробуем сделать `educ` дискретной количественной переменной.   

```{r echo = F, warning = F, error = F}
df.train$educ <- as.numeric(df.train$educ)
df.test$educ <- as.numeric(df.test$educ)

model.6 <- 

```

Эта модель лучше, но по характеристикам качества очень слабая. Пробуем добавить взаимодействие `exper:male`.  

```{r echo = F, warning = F, error = F}
df.train$educ <- as.numeric(df.train$educ)

model.7 <- 

```

Очевидно, стоит остановиться на модели без взаимодействий. Проверим её остатки.   

# Проверка остатков  

```{r echo = F, warning = F, error = F}
# тест Бройша-Пагана


# статистика Дарбина-Уотсона


# графики остатков
par(mar = c(4.5, 4.5, 2, 1))
par(mfrow = c(1, 3))
# график 1

# график 2

# график 3

par(mfrow = c(1, 1))

```

# Сравнение с kNN

```{r echo = F}
# линейная модель


# kNN требует на вход только числовые переменные


# цикл по k
for (i in 2:50){
    model.knn <- 
    y.model.knn <- 
    if (i == 2){
        MSE.knn <- 
    } else {
        MSE.knn <- 
    }
}

# график
par(mar = c(4.5, 4.5, 1, 1))
plot(2:50, MSE.knn, type = 'b', col = 'darkgreen',
     xlab = 'значение k', ylab = 'MSE на тестовой выборке')
lines(2:50, rep(MSE.lm, 49), lwd = 2, col = grey(0.2), lty = 2)
legend(15, 2.5e+10, lty = c(1, 2), pch = c(1, NA), 
       col = c('darkgreen', grey(0.2)), 
       legend = c('k ближайших соседа', 'регрессия (все факторы)'), 
       lwd = rep(2, 2))
```

